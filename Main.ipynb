{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#LAB AI PROJECT 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pylidc as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Code for feature extraction using pyradiomics and dependencies: dcm2niix and SimpleITK. We built docker container to run the code inside:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 155\u001B[0m\n\u001B[0;32m    151\u001B[0m     df3 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([df1, df2], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    153\u001B[0m     df3\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtotal_data_obliteration.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m--> 155\u001B[0m \u001B[43mget_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[1], line 3\u001B[0m, in \u001B[0;36mget_features\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_features\u001B[39m():\n\u001B[1;32m----> 3\u001B[0m     start_time \u001B[38;5;241m=\u001B[39m \u001B[43mtime\u001B[49m\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;66;03m# put path of dataset here\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     parent_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mDiederik\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mOneDrive\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mBureaublad\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mstudie tn\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mMinor vakken Porto\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mIA CAD\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mImages+seg\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mmanifest-1698154951594\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "#Function that calculates features using the pyradiomics-dcm.py script from the oyradiomics GIT\n",
    "def get_features():\n",
    "    start_time = time.time()\n",
    "    # put path of dataset here\n",
    "    parent_dir = r\"C:\\Users\\Diederik\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\Images+seg\\manifest-1698154951594\"\n",
    "    patient_dicom_path_mounted = r\"/data/Images+seg/manifest-1698154951594/LIDC-IDRI\"\n",
    "    # get path of LIDC-IDRI directionary\n",
    "    data_dir = os.path.join(parent_dir, \"LIDC-IDRI\")\n",
    "    # give directory where docker saves files\n",
    "    docker_save_dir = r\"C:\\Users\\Diederik\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\"\n",
    "    # give the hash of the pyradiomnics docker\n",
    "    docker_hash = r\"d95ce08239e3182d8631d3492a5e4a32096d28285c3d2f10dd570d7e6d06fd01\"\n",
    "    # path to the features dict\n",
    "    features_dict = r\"/data/test/featuresDict_IBSIv7.tsv\"\n",
    "    # pyradiomics save folder\n",
    "    pyradiomics_midsave_path = r\"/data/pyradiomics converter test\"\n",
    "    # temporal dir\n",
    "    temp_dir = r\"C:\\Users\\Diederik\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\test\\temp file\"\n",
    "    parameter_file = r\"C:\\Users\\Diederik\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\test\\Pyradiomics_Params_test.yaml\"\n",
    "    data = pd.read_csv(r\"C:\\Users\\Diederik\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\test\\features.csv\")\n",
    "    df = pd.read_excel(r\"C:\\Users\\Diederik\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\test\\nodule_counts_by_patient.xlsx\")\n",
    "    df = df.drop(df.columns[[4, 5]], axis=1)\n",
    "    df.columns = ['Patient_ID', 'Total_Nodule_Count', 'NodG3','NodL3']\n",
    "    dataframe = pd.DataFrame(\n",
    "        columns=['Patient_ID', 'Nodule', ' Annotation', 'Subtlety', 'InternalStructure', 'Calcification', 'Sphericity',\n",
    "                 'Margin', 'Lobulation', 'Spiculation', 'Texture', 'Malignancy'])\n",
    "    backup = 0\n",
    "    iteration_counter = 1\n",
    "    for p_id in df['Patient_ID']:\n",
    "\n",
    "        print(\"Patient \" + str(p_id) + \"Processing\")\n",
    "        if os.path.isdir(os.path.join(data_dir, str(p_id))) == False:\n",
    "            print(\"Patient \" + str(p_id) + \" not found\")\n",
    "            continue  # if the patient folder doesn't exist, skip it\n",
    "\n",
    "        scan = pl.query(pl.Scan).filter(pl.Scan.patient_id == p_id).first()\n",
    "        nods = scan.cluster_annotations()\n",
    "\n",
    "        # path to the patient folder\n",
    "        patient_dir = os.path.join(data_dir, str(p_id))\n",
    "        # path to dicom ct-scans of patient\n",
    "        patient_dicom_path = scan.get_path_to_dicom_files()\n",
    "\n",
    "        patient_folders = os.path.join(patient_dir, os.listdir(patient_dir)[0])\n",
    "        if len(os.listdir(patient_folders))==1:\n",
    "            shutil.rmtree(os.path.join(patient_dir, os.listdir(patient_dir)[0]))\n",
    "            patient_folders = os.path.join(patient_dir, os.listdir(patient_dir)[0])\n",
    "            print(\"wrong folder removed!\")\n",
    "\n",
    "        # listing all the folders from a patient\n",
    "        patient_seg_folders = os.listdir(patient_folders)\n",
    "        for folder in patient_seg_folders:\n",
    "            if \"evaluations\" in folder:\n",
    "                shutil.rmtree(os.path.join(patient_folders,folder))\n",
    "        patient_seg_folders = os.listdir(patient_folders)\n",
    "        # saving the dicom images folder path\n",
    "        # get all seg folders for nodules later\n",
    "\n",
    "\n",
    "        #if scan is None: # if the scan is not available we continue\n",
    "        #    continue\n",
    "\n",
    "        nod = 1\n",
    "        annot = 0\n",
    "        for nodule in nods:\n",
    "            for ann in nodule:\n",
    "                if annot >= len(patient_seg_folders):\n",
    "                    continue\n",
    "                backup += 1 #backupcounter\n",
    "\n",
    "                iteration_counter += 1\n",
    "                seg_folder = os.path.join(patient_folders, patient_seg_folders[annot+1])\n",
    "\n",
    "                # check how many files are in the segmentation folder\n",
    "                seg_files = os.listdir(seg_folder)\n",
    "                if len(seg_files) <= 0:\n",
    "                    # add a row with NaN values to the dataframe\n",
    "                    data.loc[len(data)] = [None] * len(data.columns)\n",
    "                # iterating over each segmentation file\n",
    "                for file in os.listdir(seg_folder):\n",
    "                    if file.endswith(\".dcm\"):\n",
    "                        seg_file_path = os.path.join(seg_folder, file)\n",
    "                        print(\"docker run -v \\\"\" + docker_save_dir + \":/data\\\" \" + docker_hash + \" --input-image-dir \\\"/data/\" + os.path.relpath(patient_dicom_path, docker_save_dir).replace(chr(92),\"/\") +  \"\\\" --input-seg-file \\\"/data/\" + os.path.relpath(seg_file_path, docker_save_dir).replace(chr(92),\"/\") + \"\\\" --output-dir \\\"\" + pyradiomics_midsave_path + \"\\\" --volume-reconstructor dcm2niix --features-dict \\\"/data/\" + os.path.relpath(features_dict, docker_save_dir).replace(chr(92),\"/\") + \"\\\" --temp-dir \\\"/data/\" + os.path.relpath(temp_dir, docker_save_dir).replace(chr(92),\"/\") + \"\\\" --correct-mask --parameters \\\"/data/\" + os.path.relpath(parameter_file, docker_save_dir).replace(chr(92),\"/\") + \"\\\"\")\n",
    "                        os.system(\"docker run -v \\\"\" + docker_save_dir + \":/data\\\" \" + docker_hash + \" --input-image-dir \\\"/data/\" + os.path.relpath(patient_dicom_path, docker_save_dir).replace(chr(92),\"/\") +  \"\\\" --input-seg-file \\\"/data/\" + os.path.relpath(seg_file_path, docker_save_dir).replace(chr(92),\"/\") + \"\\\" --output-dir \\\"\" + pyradiomics_midsave_path + \"\\\" --volume-reconstructor dcm2niix --features-dict \\\"/data/\" + os.path.relpath(features_dict, docker_save_dir).replace(chr(92),\"/\") + \"\\\" --temp-dir \\\"/data/\" + os.path.relpath(temp_dir, docker_save_dir).replace(chr(92),\"/\") + \"\\\" --correct-mask --parameters \\\"/data/\" + os.path.relpath(parameter_file, docker_save_dir).replace(chr(92),\"/\") + \"\\\"\")\n",
    "\n",
    "                        try:\n",
    "                            testdata = pd.read_csv(r\"C:\\Users\\Diederik\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\test\\temp file\\Features\\1.csv\")\n",
    "                            #print(testdata)\n",
    "                            # append data to features.csv\n",
    "                            #print(data.info())\n",
    "                            #data = data.append(testdata)\n",
    "                            data = pd.concat([data, testdata], ignore_index=True)\n",
    "                            #print(data)\n",
    "\n",
    "\n",
    "                        except:\n",
    "                            # append a row with NaN values to the dataframe\n",
    "                            data.loc[len(data)] = [None] * len(data.columns)\n",
    "                            thisdir = os.getcwd()\n",
    "                            os.chdir(parent_dir)\n",
    "                            # write to a log file the patient name, the seg folder name and the file name\n",
    "                            log = open(\"log.txt\", \"a\")\n",
    "                            log.write(\"Failed to extract features from: \" + os.getcwd() + \"\\n\")\n",
    "                            log.write(\"SEG File: \" + file + \"\\n\\n\")\n",
    "                            os.chdir(thisdir)\n",
    "                            continue\n",
    "                        # delete temp folder\n",
    "                        os.system(\"rmdir /s /q temp\")\n",
    "                        print(\"\\n\\n\")\n",
    "                    else:\n",
    "                        # also append a row with NaN values to the dataframe\n",
    "                        data.loc[len(data)] = [None] * len(data.columns)\n",
    "\n",
    "                # create feature vector\n",
    "                feature = list(ann.feature_vals())\n",
    "                feature.insert(0, annot)\n",
    "                feature.insert(0, nod)\n",
    "                feature.insert(0, p_id)\n",
    "                dataframe.loc[len(dataframe)] = feature\n",
    "\n",
    "                thisdir = os.getcwd()\n",
    "\n",
    "                # create a backup of the dataframes every 10 iterations (every 5 annotations)\n",
    "                if backup % 10 == 0:\n",
    "                    current_time = time.time()\n",
    "                    runtime = (current_time - start_time)/60\n",
    "                    print('Iteration: ' + str(iteration_counter) + '-----Backup create------------time:' + str(runtime))\n",
    "                    os.chdir(r\"C:\\Users\\Diederik\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\test\\Backups\")\n",
    "\n",
    "                    data.to_csv(\"pyradiomicsBackup.csv\", index=False)\n",
    "                    dataframe.to_csv(\"pylidcBackup.csv\", index=False)\n",
    "\n",
    "                    df1 = pd.read_csv(\"pylidcBackup.csv\")\n",
    "                    df2 = pd.read_csv(\"pyradiomicsBackup.csv\")\n",
    "\n",
    "                    df3 = pd.concat([df1, df2], axis=1)\n",
    "                    df3.to_csv(\"total_data_obliterationBackup.csv\", index=False)\n",
    "                os.chdir(thisdir)\n",
    "\n",
    "                annot += 1\n",
    "            nod += 1\n",
    "    os.chdir(parent_dir)\n",
    "\n",
    "    dataframe.to_csv(\"pylidc.csv\", index=False)\n",
    "    data.to_csv(\"pyradiomics.csv\", index=False)\n",
    "\n",
    "    df1 = pd.read_csv(\"pylidc.csv\")\n",
    "    df2 = pd.read_csv(\"pyradiomics.csv\")\n",
    "\n",
    "    # concatenate the columns from both dataframes\n",
    "    df3 = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "    df3.to_csv(\"total_data_obliteration.csv\", index=False)\n",
    "\n",
    "#get_features()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T12:28:30.409195500Z",
     "start_time": "2023-11-02T12:28:26.980238Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Code for feature selection:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#-loading data-> backup of 29/10/2023\n",
    "#pyradiomics data\n",
    "pr_data = pd.read_csv(\"../Unsorted/Data files/CSV DATA FILES/backup 29_10/pyradiomicsBackup.csv\")\n",
    "\n",
    "#pylidc data\n",
    "pl_data = pd.read_csv(\"../Unsorted/Data files/CSV DATA FILES/backup 29_10/pylidcBackup.csv\")\n",
    "\n",
    "#total obliteration data\n",
    "df = pd.read_csv(\"../Unsorted/Data files/CSV DATA FILES/backup 29_10/total_data_obliterationBackup.csv\")\n",
    "\n",
    "def drop_columns(df):\n",
    "    #function for ropping columns manually\n",
    "    columns_to_drop = np.arange(0,10)\n",
    "    # columns_to_drop2 = np.arange(12,30)\n",
    "    # columns_to_drop = np.append(columns_to_drop,  columns_to_drop2)\n",
    "    columns_to_drop = np.append(columns_to_drop,  [11,12,13])\n",
    "    df.drop(columns=df.columns[columns_to_drop],inplace=True)\n",
    "    return df\n",
    "def cleaning_data(df):\n",
    "    df = df.drop(df[df['Malignancy'] == 3].index)\n",
    "    # Remove rows with NaN values in the \"Malignancy\" column\n",
    "    df.dropna(subset=[\"Malignancy\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "def normalize_data(df):\n",
    "    normalized_data = (df-df.min())/(df.max()-df.min())\n",
    "    return normalized_data\n",
    "\n",
    "def create_category_column(df):\n",
    "    # Create a new \"Category\" column based on the \"Malignancy\" values\n",
    "    df[\"Category\"] = df[\"Malignancy\"].apply(lambda x: 1 if x in [4, 5] else 0)\n",
    "    # drop all categories which are not numerical\n",
    "    df = df.select_dtypes(include=[int, float])\n",
    "    return df\n",
    "\n",
    "def get_malignancy_column_dtype(df):\n",
    "    # Check if the \"Malignancy\" column exists in the DataFrame\n",
    "    if \"Malignancy\" in df.columns:\n",
    "        malignancy_dtype = df[\"Malignancy\"].dtype\n",
    "        return malignancy_dtype\n",
    "    else:\n",
    "        return \"Column 'Malignancy' not found in the DataFrame.\"\n",
    "\n",
    "\n",
    "df = cleaning_data(df)\n",
    "get_malignancy_column_dtype(df)\n",
    "df = create_category_column(df)\n",
    "df_norm = normalize_data(df)\n",
    "#df_norm_form = drop_columns(df_norm)\n",
    "print(df[\"Malignancy\"])\n",
    "print(df[\"Category\"])\n",
    "print(df_norm)\n",
    "\n",
    "#getting rid of features with low variance\n",
    "#sel = VarianceThreshold(threshold=0)\n",
    "#sel.fit_transform(tot_data)\n",
    "#print(tot_data)\n",
    "\n",
    "df_norm.to_csv(r\"C:\\Users\\Diederik\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\test\\backup 29_10\\filewip.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T12:28:30.641191200Z",
     "start_time": "2023-11-02T12:28:30.431096600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-02T12:28:30.433108Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-02T12:28:30.433108Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-02T12:28:30.434571600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-02T12:28:30.440641300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-02T12:28:30.450164700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-02T12:28:30.454162100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
