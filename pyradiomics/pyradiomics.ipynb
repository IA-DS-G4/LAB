{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "import sklearn\n",
    "from sklearn.linear_model import SGDRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T14:03:09.768537600Z",
     "start_time": "2023-11-04T14:03:09.705620Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pyradiomics model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Table of Contents\n",
    "1. [Feature extraction](#feature-extraction)\n",
    "2. [Feature selection](#feature-selection)\n",
    "3. [Model 1: Linear Support Vector Classifier](#model1)\n",
    "4. [Model 2: Stochastic Gradient Descent Regressor](#model2)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. <a id='feature-extraction'>Feature extraction</a>\n",
    "\n",
    "Code for feature extraction using pyradiomics and dependencies: dcm2niix and SimpleITK. We built a docker image for running the pyradiomics-dcm.py script that is available on the pyradiomics github under labs. The script was still experimental and outdated so we had to make adjustments in the script and dockerfile to make it run. If you want to install the docker container yourself we can provide the working dockerfile. \n",
    "The Feature extraction uses the pylidc library and to channel directories and read out the corresponding segmentation and icom files for each patient. These then get passed to the pyradiomics docker container with the experimental script for evaluation. \n",
    "The result is a vector with 1574 features. These are put together with metadata and saved inside a csv file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "#Function that calculates features using the pyradiomics-dcm.py script from the pyradiomics GIT\n",
    "def get_features():\n",
    "    ###################### put the working directories here ###################################\n",
    "    start_time = time.time()\n",
    "    # put path of dataset here\n",
    "    parent_dir = r\"/Images+seg/manifest-1698768984202\"\n",
    "    # this is the path which is accessed by the docker container to load and save files and so on\n",
    "    patient_dicom_path_mounted = r\"/data/Images+seg/manifest-1698768984202/LIDC-IDRI\"\n",
    "    # get path of LIDC-IDRI directionary\n",
    "    data_dir = os.path.join(parent_dir, \"LIDC-IDRI\")\n",
    "    # give directory where docker saves files\n",
    "    docker_save_dir = r\"/\"\n",
    "    # give the hash of the pyradiomnics docker\n",
    "    docker_hash = r\"d95ce08239e3182d8631d3492a5e4a32096d28285c3d2f10dd570d7e6d06fd01\"\n",
    "    # path to the features dict\n",
    "    features_dict = r\"/data/test/featuresDict_IBSIv7.tsv\"\n",
    "    # pyradiomics save folder\n",
    "    pyradiomics_midsave_path = r\"/data/pyradiomics converter test\"\n",
    "    # temporal dir\n",
    "    temp_dir = r\"/test/temp file\"\n",
    "    parameter_file = r\"/test/Pyradiomics_Params_test.yaml\"\n",
    "    ########################################################################################\n",
    "    # create dataframes for data storage\n",
    "    data = pd.read_csv(r\"/test/features.csv\")\n",
    "    data = data.drop(0, axis=0)\n",
    "    df = pd.read_excel(r\"C:\\Users\\Diederik\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\test\\nodule_counts_by_patient.xlsx\")\n",
    "    df = df.drop(df.columns[[4, 5]], axis=1)\n",
    "    df.columns = ['Patient_ID', 'Total_Nodule_Count', 'NodG3','NodL3']\n",
    "    dataframe = pd.DataFrame(\n",
    "        columns=['Patient_ID', 'Nodule', ' Annotation', 'Subtlety', 'InternalStructure', 'Calcification', 'Sphericity',\n",
    "                 'Margin', 'Lobulation', 'Spiculation', 'Texture', 'Malignancy'])\n",
    "    iteration_counter = 1\n",
    "\n",
    "\n",
    "# We process each patient chronologically\n",
    "    for p_id in df['Patient_ID']:\n",
    "\n",
    "        print(\"Patient \" + str(p_id) + \"Processing\")\n",
    "        if os.path.isdir(os.path.join(data_dir, str(p_id))) == False:\n",
    "            print(\"Patient \" + str(p_id) + \" not found\")\n",
    "            continue  # if the patient folder doesn't exist, skip it\n",
    "\n",
    "        scan = pl.query(pl.Scan).filter(pl.Scan.patient_id == p_id).first()\n",
    "        nods = scan.cluster_annotations()\n",
    "\n",
    "        if scan is None:  # if the scan is not available, continue\n",
    "            continue\n",
    "\n",
    "        # path to the patient folder\n",
    "        patient_dir = os.path.join(data_dir, str(p_id))\n",
    "        # path to dicom ct-scans of patient\n",
    "        patient_dicom_path = scan.get_path_to_dicom_files()\n",
    "        patient_folders = os.path.abspath(os.path.join(patient_dicom_path, os.pardir))\n",
    "        # listing all the folders from a patient\n",
    "        patient_seg_folders = os.listdir(patient_folders)\n",
    "        # remove the unecessary evaluations folders\n",
    "        for folder in patient_seg_folders:\n",
    "            if \"evaluations\" in folder:\n",
    "                shutil.rmtree(os.path.join(patient_folders,folder))\n",
    "        patient_seg_folders = os.listdir(patient_folders)\n",
    "        # saving the dicom images folder path\n",
    "\n",
    "        nod = 1\n",
    "        annot = 0\n",
    "\n",
    "        # find the first segmentation folder for each nodule\n",
    "        for nodule in nods:\n",
    "            ann = nodule[0]\n",
    "            for folder in patient_seg_folders:\n",
    "                if \"Nodule {}\".format(nod) in folder:\n",
    "                    seg_folder = os.path.join(patient_folders, folder)\n",
    "                    break\n",
    "\n",
    "            iteration_counter += 1\n",
    "\n",
    "            # check how many files are in the segmentation folder\n",
    "            seg_files = os.listdir(seg_folder)\n",
    "            if len(seg_files) == 0:\n",
    "                # add a row with NaN values to the dataframe\n",
    "                data.loc[len(data)] = [None] * len(data.columns)\n",
    "            # iterating over each nodule segmentation file\n",
    "            for file in os.listdir(seg_folder):\n",
    "                if file.endswith(\".dcm\"):\n",
    "                    seg_file_path = os.path.join(seg_folder, file)\n",
    "                    # os.system(\"docker run -v \\\"\" + docker_save_dir + \":/data\\\" \" + docker_hash + \" --input-image-dir \\\"/data/\" + os.path.relpath(patient_dicom_path, docker_save_dir).replace(chr(92),\"/\") +  \"\\\" --input-seg-file \\\"/data/\" + os.path.relpath(seg_file_path, docker_save_dir).replace(chr(92),\"/\") + \"\\\" --output-dir \\\"\" + pyradiomics_midsave_path + \"\\\" --volume-reconstructor dcm2niix --features-dict \\\"/data/\" + os.path.relpath(features_dict, docker_save_dir).replace(chr(92),\"/\") + \"\\\" --temp-dir \\\"/data/\" + os.path.relpath(temp_dir, docker_save_dir).replace(chr(92),\"/\") + \"\\\" --correct-mask --parameters \\\"/data/\" + os.path.relpath(parameter_file, docker_save_dir).replace(chr(92),\"/\") + \"\\\"\")\n",
    "                    docker_command = (\n",
    "                        f\"docker run -v \\\"{docker_save_dir}:/data\\\" {docker_hash} \"\n",
    "                        f\"--input-image-dir \\\"/data/{os.path.relpath(patient_dicom_path, docker_save_dir).replace(chr(92), '/')}\\\" \"\n",
    "                        f\"--input-seg-file \\\"/data/{os.path.relpath(seg_file_path, docker_save_dir).replace(chr(92), '/')}\\\" \"\n",
    "                        f\"--output-dir \\\"{pyradiomics_midsave_path}\\\" \"\n",
    "                        f\"--volume-reconstructor dcm2niix \"\n",
    "                        f\"--features-dict \\\"/data/{os.path.relpath(features_dict, docker_save_dir).replace(chr(92), '/')}\\\" \"\n",
    "                        f\"--temp-dir \\\"/data/{os.path.relpath(temp_dir, docker_save_dir).replace(chr(92), '/')}\\\" \"\n",
    "                        f\"--correct-mask \"\n",
    "                        f\"--parameters \\\"/data/{os.path.relpath(parameter_file, docker_save_dir).replace(chr(92), '/')}\\\"\"\n",
    "                    )\n",
    "                    # running in parallel for better performance\n",
    "                    subprocess.run(docker_command, shell=True)\n",
    "\n",
    "                    try:\n",
    "                        testdata = pd.read_csv(\n",
    "                            r\"/test/temp file/Features/1.csv\")\n",
    "                        data = pd.concat([data, testdata], ignore_index=True)\n",
    "                    except:\n",
    "                        # append a row with NaN values to the dataframe\n",
    "                        data.loc[len(data)] = [None] * len(data.columns)\n",
    "                        thisdir = os.getcwd()\n",
    "                        os.chdir(parent_dir)\n",
    "                        # write to a log file the patient name, the seg folder name and the file name\n",
    "                        log = open(\"log.txt\", \"a\")\n",
    "                        log.write(\"Failed to extract features from: \" + os.getcwd() + \"\\n\")\n",
    "                        log.write(\"SEG File: \" + file + \"\\n\\n\")\n",
    "                        os.chdir(thisdir)\n",
    "                        continue\n",
    "                    # delete temp folder\n",
    "                    os.system(\"rmdir /s /q temp\")\n",
    "                    print(\"\\n\\n\")\n",
    "                else:\n",
    "                    # also append a row with NaN values to the dataframe\n",
    "                    data.loc[len(data)] = [None] * len(data.columns)\n",
    "\n",
    "            # create feature vector\n",
    "            feature = list(ann.feature_vals())\n",
    "            feature.insert(0, annot)\n",
    "            feature.insert(0, nod)\n",
    "            feature.insert(0, p_id)\n",
    "            dataframe.loc[len(dataframe)] = feature\n",
    "\n",
    "            thisdir = os.getcwd()\n",
    "\n",
    "            # create a backup of the dataframes every 15 iterations\n",
    "            if iteration_counter % 15 == 0:\n",
    "                current_time = time.time()\n",
    "                runtime = (current_time - start_time) / 60\n",
    "                print('Iteration: ' + str(iteration_counter) + '-----Backup create------------time:' + str(runtime))\n",
    "                os.chdir(r\"/test/Backups\")\n",
    "\n",
    "                data.to_csv(\"pyradiomicsBackup.csv\", index=False)\n",
    "                dataframe.to_csv(\"pylidcBackup.csv\", index=False)\n",
    "\n",
    "            os.chdir(thisdir)\n",
    "\n",
    "            nod += 1\n",
    "    os.chdir(parent_dir)\n",
    "\n",
    "    dataframe.to_csv(\"pylidc.csv\", index=False)\n",
    "    data.to_csv(\"pyradiomics.csv\", index=False)\n",
    "\n",
    "# to run this code you need to built a docker container and pass the directory of the files and the name of the docker.\n",
    "# we can also provide the dockerfile we wrote\n",
    "# #get_features()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T14:03:09.853582600Z",
     "start_time": "2023-11-04T14:03:09.727838Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. <a id='feature-selection'>Feature selection</a>\n",
    "Since the model is inefficient and vulnerable to overfitting if we would use all the GLCM features, we use a statistical p-test (ANOVA) to select the most significant features for the learning model. We also clean and normalize the data so it can be used for ML algorithms. After the feature extraction using pyradiomics alot of NaN values were calculated, these features can't be used and are removed.\n",
    "The following code was used for feature selection."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diederik\\AppData\\Local\\Temp\\ipykernel_24548\\3950264260.py:5: DtypeWarning: Columns (37,38,39,40,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pr_data = pd.read_csv(\"../Unsorted/Data files/CSV DATA FILES/backup_03_11_2023_total/pyradiomics_total.csv\")\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'ML pyradiomics/total_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[51], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m#Combining pylidc and pyradiomics data\u001B[39;00m\n\u001B[0;32m      8\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([pl_data, pr_data], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 9\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mML pyradiomics/total_data.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcleaning_data\u001B[39m(df):\n\u001B[0;32m     12\u001B[0m     df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mselect_dtypes(include\u001B[38;5;241m=\u001B[39m[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mfloat\u001B[39m])\n",
      "File \u001B[1;32m~\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:3902\u001B[0m, in \u001B[0;36mNDFrame.to_csv\u001B[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001B[0m\n\u001B[0;32m   3891\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ABCDataFrame) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_frame()\n\u001B[0;32m   3893\u001B[0m formatter \u001B[38;5;241m=\u001B[39m DataFrameFormatter(\n\u001B[0;32m   3894\u001B[0m     frame\u001B[38;5;241m=\u001B[39mdf,\n\u001B[0;32m   3895\u001B[0m     header\u001B[38;5;241m=\u001B[39mheader,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3899\u001B[0m     decimal\u001B[38;5;241m=\u001B[39mdecimal,\n\u001B[0;32m   3900\u001B[0m )\n\u001B[1;32m-> 3902\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataFrameRenderer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mformatter\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3903\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3904\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlineterminator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlineterminator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3905\u001B[0m \u001B[43m    \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3906\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3907\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3908\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3909\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquoting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquoting\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3910\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3911\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3912\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3913\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3914\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquotechar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquotechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3915\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3916\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdoublequote\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdoublequote\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mescapechar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mescapechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3918\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3919\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1152\u001B[0m, in \u001B[0;36mDataFrameRenderer.to_csv\u001B[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001B[0m\n\u001B[0;32m   1131\u001B[0m     created_buffer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1133\u001B[0m csv_formatter \u001B[38;5;241m=\u001B[39m CSVFormatter(\n\u001B[0;32m   1134\u001B[0m     path_or_buf\u001B[38;5;241m=\u001B[39mpath_or_buf,\n\u001B[0;32m   1135\u001B[0m     lineterminator\u001B[38;5;241m=\u001B[39mlineterminator,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1150\u001B[0m     formatter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfmt,\n\u001B[0;32m   1151\u001B[0m )\n\u001B[1;32m-> 1152\u001B[0m \u001B[43mcsv_formatter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1154\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m created_buffer:\n\u001B[0;32m   1155\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path_or_buf, StringIO)\n",
      "File \u001B[1;32m~\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001B[0m, in \u001B[0;36mCSVFormatter.save\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    243\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    244\u001B[0m \u001B[38;5;124;03mCreate the writer & save.\u001B[39;00m\n\u001B[0;32m    245\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;66;03m# apply compression and byte/text conversion\u001B[39;00m\n\u001B[1;32m--> 247\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    248\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    249\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    250\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    251\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[0;32m    255\u001B[0m     \u001B[38;5;66;03m# Note: self.encoding is irrelevant here\u001B[39;00m\n\u001B[0;32m    256\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwriter \u001B[38;5;241m=\u001B[39m csvlib\u001B[38;5;241m.\u001B[39mwriter(\n\u001B[0;32m    257\u001B[0m         handles\u001B[38;5;241m.\u001B[39mhandle,\n\u001B[0;32m    258\u001B[0m         lineterminator\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlineterminator,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    263\u001B[0m         quotechar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquotechar,\n\u001B[0;32m    264\u001B[0m     )\n\u001B[0;32m    266\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save()\n",
      "File \u001B[1;32m~\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\venv\\Lib\\site-packages\\pandas\\io\\common.py:863\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    859\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    860\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    862\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    864\u001B[0m             handle,\n\u001B[0;32m    865\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[0;32m    866\u001B[0m             encoding\u001B[38;5;241m=\u001B[39mioargs\u001B[38;5;241m.\u001B[39mencoding,\n\u001B[0;32m    867\u001B[0m             errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[0;32m    868\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    869\u001B[0m         )\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mPermissionError\u001B[0m: [Errno 13] Permission denied: 'ML pyradiomics/total_data.csv'"
     ]
    }
   ],
   "source": [
    "#pylidc data\n",
    "pl_data = pd.read_csv(\"../Unsorted/Data files/CSV DATA FILES/backup_03_11_2023_total/pylidc_total.csv\")\n",
    "\n",
    "#pyradiomics data\n",
    "pr_data = pd.read_csv(\"../Unsorted/Data files/CSV DATA FILES/backup_03_11_2023_total/pyradiomics_total.csv\")\n",
    "\n",
    "#Combining pylidc and pyradiomics data\n",
    "df = pd.concat([pl_data, pr_data], axis=1)\n",
    "df.to_csv('ML pyradiomics/total_data.csv')\n",
    "\n",
    "def cleaning_data(df):\n",
    "    df = df.select_dtypes(include=[int, float])\n",
    "    df = df.drop(df[df['Malignancy'] == 3].index)\n",
    "    # Remove rows with NaN values in the \"Malignancy\" column\n",
    "    df.dropna(subset=[\"Malignancy\"], inplace=True)\n",
    "    threshold = df.shape[1] - 10  #  if 10 or more NaN values, drop row\n",
    "    df = df.dropna(thresh=threshold)\n",
    "    return df\n",
    "def normalize_data(df):\n",
    "    normalized_data = (df-df.min())/(df.max()-df.min())\n",
    "    return normalized_data\n",
    "\n",
    "def create_category_column(df):\n",
    "    # Create a new \"Category\" column based on the \"Malignancy\" values\n",
    "    df[\"Category\"] = df[\"Malignancy\"].apply(lambda x: 1 if x in [4, 5] else 0)\n",
    "    # drop all categories which are not numerical\n",
    "    df = df.select_dtypes(include=[int, float])\n",
    "    constant_columns = [col for col in df.columns if df[col].nunique() == 1]\n",
    "    df = df.drop(columns=constant_columns)\n",
    "    return df\n",
    "\n",
    "def get_malignancy_column_dtype(df):\n",
    "    # Check if the \"Malignancy\" column exists in the DataFrame\n",
    "    if \"Malignancy\" in df.columns:\n",
    "        malignancy_dtype = df[\"Malignancy\"].dtype\n",
    "        return malignancy_dtype\n",
    "    else:\n",
    "        return \"Column 'Malignancy' not found in the DataFrame.\"\n",
    "\n",
    "def f_selection_KBest(X,y,k=100):\n",
    "    X_new = SelectKBest(f_classif, k=k).fit_transform(X, y)\n",
    "    f_statistic, p_values = f_classif(X, y)\n",
    "    return X_new, f_statistic, p_values\n",
    "\n",
    "def f_selection_Percentile(X,y,p=10):\n",
    "    X_new = SelectPercentile(f_classif, percentile=p).fit_transform(X,y)\n",
    "    f_statistic, p_values = sklearn.feature_selection.f_classif(X,y)\n",
    "    return X_new, f_statistic, p_values\n",
    "\n",
    "def feature_select_plot(f_stat,p_val):\n",
    "    # Create a DataFrame to store and sort the F-statistic and p-values\n",
    "    results_df = pd.DataFrame({'F-Statistic': f_stat, 'p-Value': p_val})\n",
    "    results_df = results_df.sort_values(by='p-Value', ascending=True)\n",
    "    x_values = np.arange(0, len(f_stat), 1)\n",
    "\n",
    "    # Plot the sorted F-statistic and p-values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.barh(x_values, results_df['F-Statistic'], color='b')\n",
    "    plt.xlabel('F-Statistic')\n",
    "    plt.title('F-Statistic')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(x_values, -np.log10(results_df['p-Value']), color='g')\n",
    "    plt.xlabel('-log10(p-Value)')\n",
    "    plt.title('p-Values (log scale)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# get data ready for the ml model\n",
    "df = cleaning_data(df)\n",
    "#get_malignancy_column_dtype(df) for debugging\n",
    "df = create_category_column(df)\n",
    "df_norm = normalize_data(df)\n",
    "\n",
    "# Creating the ML Dataset\n",
    "X = df_norm.drop(columns=[\"Category\",\"Malignancy\"])  # X contains all columns except \"Category\"\n",
    "y = df[\"Category\"]  # y is the \"Category\" column\n",
    "y_alt = df[\"Malignancy\"]\n",
    "\n",
    "X_new, f_statistic, p_values = f_selection_Percentile(X,y)\n",
    "feature_select_plot(f_statistic,p_values)\n",
    "X_new_df = pd.DataFrame(X_new)\n",
    "\n",
    "X.to_csv(\"ML pyradiomics/X_all_cleaned.csv\", index=False)\n",
    "X_new_df.to_csv(\"ML pyradiomics/X.csv\", index=False)\n",
    "y.to_csv(\"ML pyradiomics/y.csv\", index=False)\n",
    "y_alt.to_csv(\"ML pyradiomics/y_alt.csv\", index=False)# this alternative classification uses the Malignancy score rather than a 0 or 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T15:06:00.687816500Z",
     "start_time": "2023-11-04T15:05:59.499054400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. <a id='model1'>Model 1: Linear Support Vector Classifier</a>\n",
    "Here we use the linear Support Vector Machine Classifier (LinearSVC) algorithm from the scikit package. It minimizes the loss function by updating model parameters in an iterative, stochastic way. We use this classifier is because it is particularly effective for large datasets, as it processes random subsets (mini-batches) of data, making it computationally efficient and suitable for online learning scenarios"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"ML pyradiomics/X.csv\")\n",
    "Y = pd.read_csv(\"ML pyradiomics/y.csv\")\n",
    "Y = Y.values.ravel()\n",
    "X_all = pd.read_csv(\"ML pyradiomics/X_all_cleaned.csv\")\n",
    "first_30 = np.arange(1,30,1)\n",
    "last = np.arange(35,100,5)\n",
    "feature_prop = np.append(first_30,last)\n",
    "test_size= 0.2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T15:06:03.106267Z",
     "start_time": "2023-11-04T15:06:02.702184400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#The model\n",
    "def LSVC(X,Y,iterations, test_size):\n",
    "    e = np.arange(0, iterations)\n",
    "    acc_array = np.array([])\n",
    "    model = LinearSVC(dual=True,max_iter=1000)\n",
    "    for i in e:\n",
    "        # divide training and test data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        acc_array = np.append(acc_array, accuracy)\n",
    "        #print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "    #calculate average accurcy\n",
    "    mean_acc = np.mean(acc_array)\n",
    "\n",
    "    #make a plot\n",
    "    plt.plot(e, acc_array, label='Mean value {}'.format(mean_acc))\n",
    "    plt.rcParams['font.size'] = '11'\n",
    "    #plt.figure(figsize=(8, 6), dpi=1000)\n",
    "    plt.title('Accuracy per iteration, ' + \"Dataset size: \" + str(len(X)) + ' Nodules')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "    plt.axhline(mean_acc, color='red', linestyle='dashed', label='Mean accuracy')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def feature_amount(X,Y,test_size, feature_prop):\n",
    "    acc_array = []\n",
    "    model = LinearSVC(dual=True,max_iter=1000)\n",
    "    for p in feature_prop:\n",
    "        X_new, f_statistic, p_values = f_selection_Percentile(X_all,Y,p)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_new, Y, test_size=test_size, random_state=1)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        acc_array = np.append(acc_array, accuracy)\n",
    "        max_acc = np.argmax(acc_array)\n",
    "        best_perf = feature_prop[max_acc]\n",
    "    #plotting    \n",
    "    plt.plot(feature_prop,acc_array, label='Best accuracy for: {} features used'.format(best_perf))\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy vs amount of features used')    \n",
    "    plt.ylim(0,1)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "# here we experiment which amount of features is the optimal amount for est accuracy\n",
    "feature_amount(X,Y,test_size, feature_prop)\n",
    "LSVC(X,Y,100, test_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-04T15:08:41.972312200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. <a id='model2'>Model 2: KNN</a>\n",
    "K-Nearest Neighbors (KNN) is machine learning algorithm used for classification and regression tasks. In KNN, predictions are made based on the majority class or average of the K nearest data points to a given input sample in the feature space. The choice of K, the number of neighbors, influences the model's sensitivity to local patterns. KNN is non-parametric and instance-based, meaning it doesn't make explicit assumptions about the underlying data distribution and relies on the entire dataset for predictions.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Python scrips/ML pyradiomics/X.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[54], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPython scrips/ML pyradiomics/X.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m X_all \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPython scrips/ML pyradiomics/X_all_cleaned.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      3\u001B[0m Y \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPython scrips/ML pyradiomics/y_alt.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    936\u001B[0m     dialect,\n\u001B[0;32m    937\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    944\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m    945\u001B[0m )\n\u001B[0;32m    946\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 948\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    608\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    610\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 611\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    614\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1445\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1447\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1448\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1703\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1704\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1706\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1711\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1712\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1713\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1714\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1715\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1716\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\OneDrive\\Bureaublad\\studie tn\\Minor vakken Porto\\IA CAD\\venv\\Lib\\site-packages\\pandas\\io\\common.py:863\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    859\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    860\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    862\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    864\u001B[0m             handle,\n\u001B[0;32m    865\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[0;32m    866\u001B[0m             encoding\u001B[38;5;241m=\u001B[39mioargs\u001B[38;5;241m.\u001B[39mencoding,\n\u001B[0;32m    867\u001B[0m             errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[0;32m    868\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    869\u001B[0m         )\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'Python scrips/ML pyradiomics/X.csv'"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv(\"ML pyradiomics/X.csv\")\n",
    "Y = pd.read_csv(\"ML pyradiomics/y.csv\")\n",
    "Y = Y.values.ravel()\n",
    "X_all = pd.read_csv(\"ML pyradiomics/X_all_cleaned.csv\")\n",
    "first_30 = np.arange(1,30,1)\n",
    "last = np.arange(35,100,5)\n",
    "feature_prop = np.append(first_30,last)\n",
    "test_size= 0.2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T15:11:53.816075600Z",
     "start_time": "2023-11-04T15:11:53.708149100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-04T14:03:15.932259600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
